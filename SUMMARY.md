# 📊 Ollama Demo - Итоговая сводка

## ✅ Что было создано

### 📓 Основной notebook
**`ollama_demo.ipynb`** (33 KB, 32 ячейки)
- 7 markdown ячеек (описание и заголовки)
- 25 code ячеек (код и анализ)

### 📚 Документация
1. **`OLLAMA_DEMO_README.md`** (8.6 KB) - подробная документация
2. **`БЫСТРЫЙ_СТАРТ.md`** (8.0 KB) - краткое руководство на русском

### 📁 Используемые данные
**`demo_sample.csv.gz`** (65 KB) - демо данные с обращениями клиентов

## 🎯 Три этапа обработки

```
┌─────────────────────────────────────────────────────────────┐
│  ЭТАП 1: Первичная обработка всех данных                    │
│  ────────────────────────────────────────                    │
│  • Загрузка всех обращений из demo_sample.csv.gz            │
│  • Первичное тегирование всех записей                       │
│  • Создание базового словаря тегов                          │
│  • Сохранение: results_stage1.csv, tags_dict_stage1.json    │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ЭТАП 2: Дополнительный анализ не тегнутых обращений        │
│  ──────────────────────────────────────────────────          │
│  • Фильтрация обращений БЕЗ тегов                           │
│  • Повторная обработка с детальным промптом                 │
│  • Обновление словаря тегов                                 │
│  • Сохранение: results_stage2.csv, tags_dict_stage2.json    │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  ЭТАП 3: Финальная переразметка всех обращений              │
│  ────────────────────────────────────────────                │
│  • Полная переразметка ВСЕХ обращений заново                │
│  • Использование накопленного словаря тегов                 │
│  • Создание консистентной финальной разметки                │
│  • Сохранение: results_final.csv, tags_dict_final.json      │
└─────────────────────────────────────────────────────────────┘
```

## 📋 Структура notebook

### Блок 1: Подготовка (ячейки 0-6)
```
0. [MD] Заголовок и описание
1. [MD] ## Подготовка
2. [PY] Импорт библиотек
3. [PY] Загрузка данных из demo_sample.csv.gz
4. [PY] Статистика по данным
5. [PY] Инициализация LLM и Pipeline
6. [PY] Промпт для тегирования
```

### Блок 2: Этап 1 (ячейки 7-12)
```
7.  [MD] ## Этап 1: Первичная обработка всех данных
8.  [PY] Запуск тегирования всех обращений
9.  [PY] Анализ результатов этапа 1
10. [PY] Примеры размеченных обращений
11. [PY] Словарь тегов с описаниями
12. [PY] Сохранение результатов этапа 1
```

### Блок 3: Этап 2 (ячейки 13-18)
```
13. [MD] ## Этап 2: Дополнительный анализ не тегнутых обращений
14. [PY] Фильтрация обращений без тегов
15. [PY] Повторная обработка с детальным промптом
16. [PY] Анализ результатов этапа 2
17. [PY] Сравнение этапов 1 и 2
18. [PY] Сохранение результатов этапа 2
```

### Блок 4: Этап 3 (ячейки 19-27)
```
19. [MD] ## Этап 3: Финальная переразметка всех обращений
20. [PY] Подготовка финального промпта
21. [PY] Финальная переразметка всех обращений
22. [PY] Финальная статистика
23. [PY] Топ-20 самых популярных тегов
24. [PY] Примеры финальной разметки
25. [PY] Финальный словарь тегов
26. [PY] Сравнение всех этапов
27. [PY] Сохранение финальных результатов
```

### Блок 5: Анализ качества (ячейки 28-31)
```
28. [MD] ## Анализ качества разметки
29. [PY] Анализ по типу speaker (agent/client)
30. [PY] Анализ обращений без тегов
31. [MD] ## Итоги
```

## 📊 Выходные файлы

После выполнения notebook будут созданы:

### Результаты по этапам:
```
results_stage1.csv         # Результаты этапа 1
results_stage2.csv         # Результаты этапа 2
results_final.csv          # ✅ ФИНАЛЬНЫЕ РЕЗУЛЬТАТЫ
```

### Словари тегов:
```
tags_dict_stage1.json      # Словарь тегов этапа 1
tags_dict_stage2.json      # Словарь тегов этапа 2
tags_dict_final.json       # ✅ ФИНАЛЬНЫЙ СЛОВАРЬ
```

### Анализ:
```
comparison.csv             # Сравнительная таблица всех этапов
```

## 🚀 Быстрый старт

### 1. Запустите Ollama
```bash
ollama serve
```

### 2. Установите модель
```bash
ollama pull qwen2.5:32b
```

### 3. Запустите notebook
```bash
cd /home/alex/tradeML/llm_tags
source venv/bin/activate
jupyter notebook ollama_demo.ipynb
```

### 4. Выполните все ячейки
Просто запускайте ячейки последовательно (Shift+Enter)

## ⚙️ Настройки

### Модель LLM (ячейка 5)
```python
llm = OllamaLLM(
    api_url="http://localhost:11434/api",
    model="qwen2.5:32b",      # Модель
    temperature=0.7            # Температура (0.0-1.0)
)
```

### Pipeline (ячейка 5)
```python
pipeline = TaggingPipeline(
    llm=llm,
    batch_size=50,    # Размер батча (20-100)
    num_workers=5     # Кол-во потоков (2-10)
)
```

### Рекомендации:
| Система | batch_size | num_workers |
|---------|------------|-------------|
| Быстрая (GPU) | 100 | 10 |
| Средняя | 50 | 5 |
| Медленная | 20 | 2 |

## ⏱️ Время выполнения

Для обработки **1000 обращений** на средней системе:

| Этап | Время | Описание |
|------|-------|----------|
| Этап 1 | ~15 мин | Первичная обработка всех |
| Этап 2 | ~3 мин | Только не тегнутые |
| Этап 3 | ~15 мин | Полная переразметка |
| **ИТОГО** | **~33 мин** | Полный цикл |

## 📈 Что анализируется

Notebook автоматически создает:

✅ **Статистика покрытия**
- Сколько обращений получили теги
- Сколько обращений без тегов
- Процент покрытия

✅ **Распределение тегов**
- Топ-20 самых популярных тегов
- Частота использования каждого тега
- Распределение по количеству тегов (0, 1, 2, 3)

✅ **Анализ по speaker**
- Статистика для agent
- Статистика для client
- Топ-5 тегов для каждого типа

✅ **Сравнение этапов**
- Таблица с метриками всех трех этапов
- Динамика улучшения результатов
- Рост словаря тегов

✅ **Примеры разметки**
- Случайные примеры размеченных обращений
- Обращения без тегов (если есть)
- Обращения, получившие теги на этапе 2

## 🎓 Использование

### Для обучения
Notebook идеально подходит для:
- Изучения работы с LLM через Ollama
- Понимания процесса тегирования
- Экспериментов с промптами
- Анализа качества разметки

### Для продакшена
Notebook можно использовать как:
- Шаблон для собственных задач
- Инструмент для разметки данных
- Базу для создания автоматизированных пайплайнов

### Для экспериментов
Легко изменить:
- Промпты для каждого этапа
- Параметры LLM (модель, температура)
- Параметры Pipeline (batch_size, num_workers)
- Входные данные

## 📚 Дополнительные материалы

- **`OLLAMA_DEMO_README.md`** - подробная документация (English)
- **`БЫСТРЫЙ_СТАРТ.md`** - краткое руководство (Русский)
- **`llm_tags.py`** - исходный код библиотеки
- **`example.py`** - примеры использования в Python скриптах

## 🔧 Troubleshooting

### Ollama не запускается
```bash
ps aux | grep ollama        # Проверка
pkill ollama                # Остановка
ollama serve                # Запуск
```

### Модель не найдена
```bash
ollama list                 # Список моделей
ollama pull qwen2.5:32b     # Установка
```

### Медленная работа
- Уменьшите `batch_size` и `num_workers`
- Используйте более легкую модель (qwen2.5:7b)
- Проверьте нагрузку на систему

### Out of Memory
- Уменьшите `batch_size` до 10-20
- Уменьшите `num_workers` до 1-2
- Закройте другие приложения

## 🎯 Следующие шаги

1. ✅ Запустите notebook с демо данными
2. ✅ Изучите результаты и анализ
3. ✅ Экспериментируйте с промптами
4. ✅ Попробуйте свои данные
5. ✅ Настройте под свои задачи

---

**Создано:** 30 ноября 2025  
**Версия:** 1.0  
**Статус:** ✅ Готово к использованию

**Успехов в работе с llm_tags! 🚀**


#!/usr/bin/env python3
"""
Демонстрация разницы между последовательной и параллельной обработкой батчей.

ПОСЛЕДОВАТЕЛЬНАЯ (num_workers=1):
- Каждый батч видит теги, найденные в предыдущих батчах
- Медленнее, но более консистентные теги
- Рекомендуется для первой итерации обработки данных

ПАРАЛЛЕЛЬНАЯ (num_workers>1):
- Все батчи обрабатываются одновременно с одинаковым начальным словарем тегов
- Быстрее, но возможны похожие теги из разных батчей
- Рекомендуется для последующих итераций, когда теги уже накоплены
"""

import pandas as pd
from llm_tags import TaggingPipeline, OllamaLLM

# Создаем тестовые данные - 12 обращений (3 батча по 4)
test_df = pd.DataFrame({
    "text": [
        # Батч 1 - проблемы с авторизацией
        "Не могу войти в личный кабинет",
        "Забыл пароль от аккаунта",
        "Не приходит код подтверждения",
        "Заблокирован доступ к аккаунту",
        
        # Батч 2 - похожие проблемы (должны переиспользовать теги из батча 1)
        "Не могу зайти в систему",
        "Потерял пароль",
        "Не получаю SMS с кодом",
        "Аккаунт заблокирован",
        
        # Батч 3 - новые проблемы
        "Медленный интернет",
        "Не работает роуминг",
        "Хочу изменить тариф",
        "Списали лишние деньги",
    ]
})

# Простой промпт
prompt = """Проанализируй обращения клиентов телеком-оператора и определи теги.
Теги должны отражать основную тему обращения."""

print("=" * 80)
print("ДЕМОНСТРАЦИЯ: ПОСЛЕДОВАТЕЛЬНАЯ vs ПАРАЛЛЕЛЬНАЯ ОБРАБОТКА")
print("=" * 80)

# ============================================================================
# ВАРИАНТ 1: ПОСЛЕДОВАТЕЛЬНАЯ ОБРАБОТКА (num_workers=1)
# ============================================================================
print("\n" + "=" * 80)
print("ВАРИАНТ 1: ПОСЛЕДОВАТЕЛЬНАЯ ОБРАБОТКА (num_workers=1)")
print("=" * 80)
print("Каждый батч видит теги предыдущих батчей")
print("Ожидается: батч 2 переиспользует теги из батча 1")
print("-" * 80)

llm = OllamaLLM()
pipeline_seq = TaggingPipeline(llm=llm, batch_size=4, num_workers=1)

result_seq, tags_seq = pipeline_seq.tag(
    test_df,
    text_column="text",
    tag_prompt=prompt,
    max_tags=2
)

print("\nРезультаты последовательной обработки:")
print(result_seq[["text", "tags"]])
print(f"\nВсего уникальных тегов: {len(tags_seq)}")
print("\nСловарь тегов:")
for i, (tag, desc) in enumerate(tags_seq.items(), 1):
    print(f"  {i}. {tag}: {desc}")

# ============================================================================
# ВАРИАНТ 2: ПАРАЛЛЕЛЬНАЯ ОБРАБОТКА (num_workers=3)
# ============================================================================
print("\n" + "=" * 80)
print("ВАРИАНТ 2: ПАРАЛЛЕЛЬНАЯ ОБРАБОТКА (num_workers=3)")
print("=" * 80)
print("Все батчи обрабатываются одновременно с пустым словарем тегов")
print("Ожидается: батч 2 может создать похожие теги вместо переиспользования")
print("-" * 80)

pipeline_par = TaggingPipeline(llm=llm, batch_size=4, num_workers=3)

result_par, tags_par = pipeline_par.tag(
    test_df,
    text_column="text",
    tag_prompt=prompt,
    max_tags=2
)

print("\nРезультаты параллельной обработки:")
print(result_par[["text", "tags"]])
print(f"\nВсего уникальных тегов: {len(tags_par)}")
print("\nСловарь тегов:")
for i, (tag, desc) in enumerate(tags_par.items(), 1):
    print(f"  {i}. {tag}: {desc}")

# ============================================================================
# СРАВНЕНИЕ
# ============================================================================
print("\n" + "=" * 80)
print("СРАВНЕНИЕ РЕЗУЛЬТАТОВ")
print("=" * 80)
print(f"Последовательная обработка: {len(tags_seq)} уникальных тегов")
print(f"Параллельная обработка:     {len(tags_par)} уникальных тегов")
print()
print("РЕКОМЕНДАЦИИ:")
print("-" * 80)
print("1. ПЕРВАЯ ИТЕРАЦИЯ (создание словаря тегов):")
print("   Используйте num_workers=1 для накопления консистентных тегов")
print()
print("2. ПОСЛЕДУЮЩИЕ ИТЕРАЦИИ (словарь тегов уже есть):")
print("   Используйте num_workers=5 для ускорения обработки")
print("   Передавайте existing_tags из предыдущей итерации")
print()
print("Пример:")
print("```python")
print("# Первая итерация - создаем словарь тегов")
print("pipeline = TaggingPipeline(llm=llm, num_workers=1)")
print("result1, tags1 = pipeline.tag(df1, text_column='text', tag_prompt=prompt)")
print()
print("# Вторая итерация - используем накопленные теги")
print("pipeline = TaggingPipeline(llm=llm, num_workers=5)")
print("result2, tags2 = pipeline.tag(df2, text_column='text', tag_prompt=prompt, existing_tags=tags1)")
print("```")
print("=" * 80)


# Решение проблемы с малым количеством тегов

## Диагностика проблемы

После тестирования выявлено, что **модель `qwen3:32b` с параметром `"format": "json"` возвращает один JSON объект вместо массива**, даже когда явно указано вернуть массив.

### Что происходит:

Запрос: 50 обращений → Ожидается: массив из 50 объектов  
Реальность: Модель возвращает **1 объект с общими тегами для всех обращений**

Это объясняет, почему из 1000 обращений только 4 получили теги.

## Решение

Есть 3 варианта:

### Вариант 1: Обработка по одному обращению (РЕКОМЕНДУЕТСЯ)

Изменить `batch_size=1` в pipeline:

```python
pipeline = TaggingPipeline(
    llm=llm,
    batch_size=1,      # ← Изменить с 50 на 1
    num_workers=5      # Можно увеличить до 10 для компенсации
)
```

**Плюсы:**
- Гарантированно работает
- Не требует изменения кода
- Можно увеличить `num_workers` для ускорения

**Минусы:**
- Медленнее (но с `num_workers=10` будет приемлемо)

### Вариант 2: Использовать другую модель

Попробуйте модели, которые лучше следуют инструкциям по формату:

```python
# Вариант A: Llama 3
llm = OllamaLLM(
    api_url="http://localhost:11434/api",
    model="llama3:70b",  # или llama3:8b
    temperature=0.7
)

# Вариант B: Mistral
llm = OllamaLLM(
    api_url="http://localhost:11434/api",
    model="mistral:latest",
    temperature=0.7
)
```

### Вариант 3: Убрать `"format": "json"`

Модифицировать `llm_tags.py`, убрав параметр `"format": "json"` из запроса. Это может помочь модели лучше следовать инструкциям.

## Быстрое решение (для немедленного использования)

Измените ячейку 5 в вашем notebook:

```python
# Инициализация LLM и Pipeline
llm = OllamaLLM(
    api_url="http://localhost:11434/api",
    model="qwen3:32b",
    temperature=0.7
)

pipeline = TaggingPipeline(
    llm=llm,
    batch_size=1,      # ← ИЗМЕНЕНО: было 50
    num_workers=10     # ← ИЗМЕНЕНО: было 5, увеличиваем для компенсации
)

print("✓ LLM и Pipeline инициализированы")
print(f"  Модель: {llm.model}")
print(f"  Batch size: {pipeline.batch_size}")
print(f"  Workers: {pipeline.num_workers}")
```

**Ожидаемое время обработки:**
- 1000 обращений / 10 workers ≈ 100 батчей
- ~3-5 секунд на батч
- **Общее время: 5-8 минут** (вместо 3 минут, но зато все обращения будут размечены)

## Улучшенный промпт

Также рекомендую использовать более явный промпт:

```python
tag_prompt = """
Проанализируй обращение клиента телеком-оператора Union Mobile и определи теги.

ВАЖНО: Ты ОБЯЗАН присвоить хотя бы 1 тег. Даже если контекст неясен, используй наиболее подходящий тег.

Возможные категории тегов:
- авторизация: проблемы со входом в систему, личный кабинет
- пароль: восстановление или смена пароля
- тарифы: вопросы по тарифным планам, изменение тарифа
- биллинг: вопросы по оплате, списаниям, счетам
- технические_проблемы: неполадки с услугами (интернет, звонки, SMS)
- роуминг: вопросы по роумингу
- настройки: настройка телефона, функций, приложений
- устройство: проблемы с устройством, покупка нового телефона
- sim_карта: вопросы по SIM-карте, замена, активация
- доставка: вопросы по доставке товаров/сим-карт
- жалоба: жалобы на обслуживание, качество связи
- консультация: общие вопросы, информация об услугах
- обслуживание: работа агента, приветствия, прощания, внутренние заметки
- диалог: короткие ответы клиента ("да", "нет", "спасибо")
- подтверждение: агент подтверждает действия, резюмирует договоренности
- уточнение: агент или клиент запрашивает дополнительную информацию

Правила:
1. ОБЯЗАТЕЛЬНО присвой минимум 1 тег
2. Используй от 1 до 3 наиболее релевантных тегов
3. Если это реплика агента без явной проблемы - используй "обслуживание", "подтверждение" или "уточнение"
4. Если это короткий ответ клиента - используй "диалог"
5. Создавай новые теги только если ни один из существующих не подходит

НЕДОПУСТИМО возвращать пустые теги!
"""
```

## Проверка результата

После изменений запустите:

```python
result_df, tags_dict = pipeline.tag(
    tags=df,
    text_column="text",
    tag_prompt=tag_prompt,
    id_column="request_id",
    skip_if_tags_count=999,
    max_tags=3
)

# Проверка
has_tags = result_df['tags'].apply(lambda x: bool(x and str(x).strip()))
print(f"Обращений с тегами: {has_tags.sum()}/{len(result_df)} ({has_tags.sum()/len(result_df)*100:.1f}%)")
```

Ожидаемый результат: **>95% обращений с тегами** (вместо 0.4%)

